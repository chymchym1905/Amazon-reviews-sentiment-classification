{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import gzip\n",
    "import numpy as np\n",
    "# import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Video_Games_Resampled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>style</th>\n",
       "      <th>image</th>\n",
       "      <th>Positive Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>346407</td>\n",
       "      <td>129412</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>05 3, 2010</td>\n",
       "      <td>A3DID3K8W8QD9W</td>\n",
       "      <td>B0012LHO46</td>\n",
       "      <td>Sam Hartford</td>\n",
       "      <td>bought mine ebay one amazon work fine generics...</td>\n",
       "      <td>PS2 64mb Memory Card is A-OK</td>\n",
       "      <td>1272844800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19478</td>\n",
       "      <td>204432</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>05 5, 2014</td>\n",
       "      <td>A1SPRD853KYUP1</td>\n",
       "      <td>B002I0K956</td>\n",
       "      <td>Oswaldo Romero</td>\n",
       "      <td>nice</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>1399248000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>349043</td>\n",
       "      <td>367307</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>01 4, 2017</td>\n",
       "      <td>A4SV916591F5Z</td>\n",
       "      <td>B00KY1I0IO</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>great fun addicting</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>1483488000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'Format:': ' Video Game'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>238716</td>\n",
       "      <td>381621</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>02 12, 2016</td>\n",
       "      <td>AWXOF97NP6ZZG</td>\n",
       "      <td>B00O9GPD26</td>\n",
       "      <td>Amazon Customer</td>\n",
       "      <td>surprisingly higher quality figure american ve...</td>\n",
       "      <td>The figure is better than the american version.</td>\n",
       "      <td>1455235200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>416659</td>\n",
       "      <td>456490</td>\n",
       "      <td>5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>08 5, 2005</td>\n",
       "      <td>A3LOOGDJ7S01LA</td>\n",
       "      <td>B00008J2V0</td>\n",
       "      <td>whiterabbit</td>\n",
       "      <td>highly recommended whole family easy instructi...</td>\n",
       "      <td>Lots of Fun, Lots to Explore!</td>\n",
       "      <td>1123200000</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  overall  verified   reviewTime      reviewerID  \\\n",
       "0        346407      129412      5.0     False   05 3, 2010  A3DID3K8W8QD9W   \n",
       "1         19478      204432      4.0      True   05 5, 2014  A1SPRD853KYUP1   \n",
       "2        349043      367307      5.0      True   01 4, 2017   A4SV916591F5Z   \n",
       "3        238716      381621      4.0      True  02 12, 2016   AWXOF97NP6ZZG   \n",
       "4        416659      456490      5.0     False   08 5, 2005  A3LOOGDJ7S01LA   \n",
       "\n",
       "         asin     reviewerName  \\\n",
       "0  B0012LHO46     Sam Hartford   \n",
       "1  B002I0K956   Oswaldo Romero   \n",
       "2  B00KY1I0IO  Amazon Customer   \n",
       "3  B00O9GPD26  Amazon Customer   \n",
       "4  B00008J2V0      whiterabbit   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  bought mine ebay one amazon work fine generics...   \n",
       "1                                               nice   \n",
       "2                                great fun addicting   \n",
       "3  surprisingly higher quality figure american ve...   \n",
       "4  highly recommended whole family easy instructi...   \n",
       "\n",
       "                                           summary  unixReviewTime vote  \\\n",
       "0                     PS2 64mb Memory Card is A-OK      1272844800  NaN   \n",
       "1                                       Four Stars      1399248000  NaN   \n",
       "2                                       Five Stars      1483488000  NaN   \n",
       "3  The figure is better than the american version.      1455235200  NaN   \n",
       "4                    Lots of Fun, Lots to Explore!      1123200000    7   \n",
       "\n",
       "                        style image  Positive Rating  \n",
       "0                         NaN   NaN                1  \n",
       "1                         NaN   NaN                1  \n",
       "2  {'Format:': ' Video Game'}   NaN                1  \n",
       "3                         NaN   NaN                1  \n",
       "4                         NaN   NaN                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.reindex(np.random.permutation(df.index))\n",
    "# ratingonly = df.shape\n",
    "# df = df.dropna(subset=['overall'],inplace=True)\n",
    "# df = df.dropna(subset=['reviewText'],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax=sns.countplot(x='overall', data=df)\n",
    "ax.bar_label(ax.containers[0])\n",
    "plt.grid(visible=True,axis='y',alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rating_threshold = 4\n",
    "# df['Positive Rating'] = df['overall'].apply(lambda x: 1 if x>=rating_threshold else 0)\n",
    "# df['Positive Rating'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# import re\n",
    "# from nltk.tokenize import word_tokenize, RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_text(text):\n",
    "#     # lower text\n",
    "#     text = text.lower()\n",
    "#     # remove hyperlinks\n",
    "#     text = re.compile(r'^https?://', re.IGNORECASE).sub(r'', text)\n",
    "#     # remove non-letters\n",
    "#     text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "#     text = word_tokenize(text)\n",
    "#     # remove stopwords\n",
    "#     stops = set(stopwords.words(\"english\"))\n",
    "#     text = [w for w in text if not w in stops]\n",
    "#     text = \" \".join(text)\n",
    "#     # remove punctuation\n",
    "#     text = RegexpTokenizer(r'\\w+').tokenize(text)\n",
    "#     text = \" \".join(text)\n",
    "#     # remove words less than 3 letters\n",
    "#     text = re.sub(r'\\b\\w{1,2}\\b', '', text)\n",
    "#     return text  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.dropna(subset=['reviewText'],inplace=True)\n",
    "# df['reviewText'] = df['reviewText'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils import resample\n",
    "\n",
    "# majority = df[df['Positive Rating']==1]\n",
    "# minority = df[df['Positive Rating']==0]\n",
    "# minority_upsampled = resample(minority, replace=True, n_samples=int(len(minority)*1.6), random_state=87)\n",
    "# majority_downsampled =  resample(majority, replace=True, n_samples=int(len(majority)/2.2), random_state=100)\n",
    "# resampled_df = pd.concat([majority_downsampled, minority_upsampled])\n",
    "\n",
    "# print(resampled_df.shape)\n",
    "# resampled_df['overall'].value_counts()\n",
    "# resampled_df.to_csv('Video_Games_Resampled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv('Video_Games_Resampled.csv')\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263969\n",
      "78849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "trainx, testx, trainy, testy = train_test_split(df['reviewText'], df['Positive Rating'], test_size=0.23, random_state=42)\n",
    "print(len(trainx))\n",
    "print(len(testx))\n",
    "train = pd.concat([trainx, trainy], axis =1)\n",
    "test = pd.concat([testx, testy], axis=1)\n",
    "# train.to_csv('train_data.csv', index=True)\n",
    "# test.to_csv('test_data.csv',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext.transforms as T\n",
    "eng = spacy.load(\"en_core_web_sm\")\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "def engTokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize an English text and return a list of tokens\n",
    "    \"\"\"\n",
    "    return [token.text for token in eng.tokenizer(text)]\n",
    "\n",
    "def tokenize(data):\n",
    "    for x in data:\n",
    "        yield engTokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_train = build_vocab_from_iterator(\n",
    "    tokenize(trainx),\n",
    "    min_freq=2,\n",
    "    specials= ['<pad>', '<sos>', '<eos>', '<unk>'],\n",
    "    special_first=True\n",
    ")\n",
    "vocab_train.set_default_index(vocab_train['<unk>'])\n",
    "vocab_test = build_vocab_from_iterator(\n",
    "    tokenize(testx),\n",
    "    min_freq=2,\n",
    "    specials= ['<pad>', '<sos>', '<eos>', '<unk>'],\n",
    "    special_first=True\n",
    ")\n",
    "vocab_test.set_default_index(vocab_test['<unk>'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load vocab train\n",
      "Load vocab test\n",
      "['<pad>', '<sos>', '<eos>', '<unk>', 'game', ' ', 'like', 'one', 'games', 'get', 'play', 'good', 'really', 'time', 'great', 'fun', 'would', 'much', 'even', 'first', 'also', 'well', 'graphics', 'story', 'new', 'playing', 'way', 'better', 'still', 'make', 'use', 'played', 'many', 'could', 'lot', 'want', 'back', 'little', 'pretty', 'buy', 'gameplay', 'bad', 'people', 'best', 'got']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "if os.path.exists('vocab_train.pkl'):\n",
    "    print('Load vocab train')\n",
    "    with open('vocab_train.pkl', 'rb') as vocab_train_file:\n",
    "        vocab_train = pickle.load(vocab_train_file)\n",
    "else:\n",
    "    # Save the trained vocab_train\n",
    "    print('Save vocab train')\n",
    "    with open('vocab_train.pkl', 'wb') as vocab_train_file:\n",
    "        pickle.dump(vocab_train, vocab_train_file)\n",
    "\n",
    "if os.path.exists('vocab_test.pkl'):\n",
    "    print('Load vocab test')\n",
    "    # Load vocab_test from the pickle file\n",
    "    with open('vocab_test.pkl', 'rb') as vocab_test_file:\n",
    "        vocab_test = pickle.load(vocab_test_file)\n",
    "else:\n",
    "    print('Save vocab test')\n",
    "    # Save the trained vocab_test\n",
    "    with open('vocab_test.pkl', 'wb') as vocab_test_file:\n",
    "        pickle.dump(vocab_test, vocab_test_file)\n",
    "\n",
    "\n",
    "print(vocab_train.get_itos()[:45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77587\n"
     ]
    }
   ],
   "source": [
    "vocabsize = len(vocab_train)\n",
    "print(vocabsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the dimensions\n",
    "input_dim = vocabsize # The dimension of your input data (e.g., vocabulary size)\n",
    "hidden_dim = 256  # Size of the hidden layer\n",
    "embedding_dim =  128\n",
    "output_dim = 2  # Two classes: positive and negative\n",
    "learning_rate = 0.001\n",
    "epochs = 15\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the classification model\n",
    "class SentimentClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
    "        # self.rnn = torch.nn.RNN(embedding_dim,\n",
    "        #                        hidden_dim,\n",
    "        #                        nonlinearity='relu')\n",
    "        self.rnn = torch.nn.LSTM(input_size= embedding_dim,\n",
    "                                 hidden_size=hidden_dim)        \n",
    "        \n",
    "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, text, length):\n",
    "        # text dim: [sentence length, batch size]\n",
    "        \n",
    "        embedded = self.embedding(text)\n",
    "        # embedded dim: [sentence length, batch size, embedding dim]\n",
    "        # Pack the sequences for efficient processing\n",
    "        packed_data = pack_padded_sequence(embedded, length.sum(1), batch_first=True, enforce_sorted=False)\n",
    "        output, (hidden, cell) = self.rnn(packed_data)\n",
    "        # output dim: [sentence length, batch size, hidden dim]\n",
    "        # hidden dim: [1, batch size, hidden dim]\n",
    "        unpacked_output, unpacked_length = pad_packed_sequence(output,batch_first=True)\n",
    "        unpacked_output.squeeze_(1)\n",
    "        # hidden dim: [batch size, hidden dim]\n",
    "        o = self.fc(unpacked_output)\n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # sample = {'data': self.data[idx], 'label': self.labels[idx]}\n",
    "        return self.data.iloc[idx], self.labels[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_train = trainy.values\n",
    "y_test = testy.values\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTransform(vocab):\n",
    "    \"\"\"\n",
    "    Create transforms based on given vocabulary. The returned transform is applied to sequence\n",
    "    of tokens.\n",
    "    \"\"\"\n",
    "    text_tranform = T.Sequential(\n",
    "        ## converts the sentences to indices based on given vocabulary\n",
    "        T.VocabTransform(vocab=vocab),\n",
    "        ## Add <sos> at beginning of each sentence. 1 because the index for <sos> in vocabulary is\n",
    "        # 1 as seen in previous section\n",
    "        T.AddToken(1, begin=True),\n",
    "        ## Add <eos> at beginning of each sentence. 2 because the index for <eos> in vocabulary is\n",
    "        # 2 as seen in previous section\n",
    "        T.AddToken(2, begin=False)\n",
    "    )\n",
    "    return text_tranform\n",
    "def applyTransform(text):\n",
    "    \"\"\"\n",
    "    Apply transforms to sequence of tokens in a sequence pair\n",
    "    \"\"\"\n",
    "\n",
    "    return getTransform(vocab_train)(engTokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1650, 716, 186, 474, 1775, 93, 27, 2180, 420, 5953, 23089, 474, 27, 6830, 2]\n",
      "[1, 103, 887, 3489, 7, 326, 67, 279, 27881, 278, 973, 42, 250, 27881, 12294, 4811, 72, 3159, 450, 323, 21, 9, 2614, 8177, 11446, 4811, 134, 36, 5, 3263, 116, 37, 2249, 116, 686, 2035, 1272, 450, 1472, 4811, 289, 1193, 2629, 45, 15703, 1451, 203, 12540, 1918, 5, 973, 67, 279, 1410, 11, 2165, 1272, 450, 1026, 250, 1877, 617, 617, 6423, 151, 444, 7, 973, 79, 137, 7, 716, 186, 4136, 4617, 785, 450, 33, 133, 2329, 1335, 272, 1058, 5931, 53, 5, 450, 62, 150, 39, 2]\n"
     ]
    }
   ],
   "source": [
    "x_train = trainx.apply(applyTransform)\n",
    "temp = list(x_train)\n",
    "print(x_train[3])\n",
    "x_test = testx.apply(applyTransform)\n",
    "temp=list(x_test)\n",
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available. Using GPU.\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.set_device(0)\n",
    "    print(\"GPU available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available. Using CPU.\")\n",
    "print(device)\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    data, labels = zip(*batch)\n",
    "\n",
    "    # Sort sequences by length (from longest to shortest)\n",
    "    sorted_data, sorted_labels = zip(*sorted(zip(data, labels), key=lambda x: len(x[0]), reverse=True))\n",
    "\n",
    "    # Pad sequences to the length of the longest sequence\n",
    "    padded_data = pad_sequence([torch.tensor(seq) for seq in sorted_data], batch_first=True)\n",
    "    padded_labels = torch.tensor(sorted_labels, dtype=torch.long)\n",
    "    onehot_padded_labels = F.one_hot(padded_labels, num_classes=2)\n",
    "\n",
    "    # Create a mask for the padded elements\n",
    "    mask = (padded_data != 0).float()\n",
    "\n",
    "    return padded_data.to(device), mask, onehot_padded_labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(x_train, y_train)\n",
    "testset = CustomDataset(x_test, y_test)\n",
    "\n",
    "# trainset = CustomDataset(vocab_train, y_train_onehot)\n",
    "# testset = CustomDataset(vocab_test, y_test)\n",
    "\n",
    "# Create a DataLoader for your dataset\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "# Move your model to the GPU\n",
    "\n",
    "# Instantiate the classifier\n",
    "model = SentimentClassifier(input_dim, embedding_dim, hidden_dim, output_dim).to(device)\n",
    "# Define the loss function (cross-entropy) and the optimizer (Adam)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    1,     5,     7,  ..., 18416,   363,     2],\n",
      "        [    1,   142,     5,  ...,     0,     0,     0],\n",
      "        [    1,    19,    35,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [    1,   115,     2,  ...,     0,     0,     0],\n",
      "        [    1, 13016,     2,  ...,     0,     0,     0],\n",
      "        [    1,    11,     2,  ...,     0,     0,     0]], device='cuda:0')\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
      "        [1., 1., 1.,  ..., 0., 0., 0.]])\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n",
      "tensor([[1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [1, 0],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1],\n",
      "        [0, 1]], device='cuda:0')\n",
      "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\n"
     ]
    }
   ],
   "source": [
    "for x,y,z in train_loader:\n",
    "    print(x)\n",
    "    print('AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA')\n",
    "    print(y)\n",
    "    print('AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA')\n",
    "    print(z)\n",
    "    print('AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA')\n",
    "    # seq_unpacked, lens_unpacked = pad_packed_sequence(x, batch_first=True)\n",
    "    # print(seq_unpacked)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2063 [00:00<?, ?batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 2063/2063 [20:51<00:00,  1.65batch/s]\n",
      "100%|| 2063/2063 [20:51<00:00,  1.65batch/s, loss=1.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 617/617 [00:48<00:00, 12.77batch/s, accuracy=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15] | Test Accuracy: 100.00%\n",
      "Training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|       | 483/2063 [03:35<11:43,  2.25batch/s, loss=1.31]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mi:\\Bch Khoa\\CO3029\\mini project\\main.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/i%3A/B%C3%A1ch%20Khoa/CO3029/mini%20project/main.ipynb#X34sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# Wrap train_loader with tqdm to display progress bar\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/B%C3%A1ch%20Khoa/CO3029/mini%20project/main.ipynb#X34sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mwith\u001b[39;00m tqdm(tepoch, unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m tbatch:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/i%3A/B%C3%A1ch%20Khoa/CO3029/mini%20project/main.ipynb#X34sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39mfor\u001b[39;00m packed_data, mask, labels \u001b[39min\u001b[39;00m tbatch:\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/B%C3%A1ch%20Khoa/CO3029/mini%20project/main.ipynb#X34sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/B%C3%A1ch%20Khoa/CO3029/mini%20project/main.ipynb#X34sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         predictions \u001b[39m=\u001b[39m model(packed_data, mask)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\std.py:1170\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1167\u001b[0m \u001b[39m# If the bar is disabled, then just walk the iterable\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m \u001b[39m# (note: keep this check outside the loop for performance)\u001b[39;00m\n\u001b[0;32m   1169\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisable:\n\u001b[1;32m-> 1170\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1171\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1172\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "\u001b[1;32mi:\\Bch Khoa\\CO3029\\mini project\\main.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/B%C3%A1ch%20Khoa/CO3029/mini%20project/main.ipynb#X34sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m sorted_data, sorted_labels \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39msorted\u001b[39m(\u001b[39mzip\u001b[39m(data, labels), key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mlen\u001b[39m(x[\u001b[39m0\u001b[39m]), reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/B%C3%A1ch%20Khoa/CO3029/mini%20project/main.ipynb#X34sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Pad sequences to the length of the longest sequence\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/i%3A/B%C3%A1ch%20Khoa/CO3029/mini%20project/main.ipynb#X34sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m padded_data \u001b[39m=\u001b[39m pad_sequence([torch\u001b[39m.\u001b[39mtensor(seq) \u001b[39mfor\u001b[39;00m seq \u001b[39min\u001b[39;00m sorted_data], batch_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/B%C3%A1ch%20Khoa/CO3029/mini%20project/main.ipynb#X34sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m padded_labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(sorted_labels, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/B%C3%A1ch%20Khoa/CO3029/mini%20project/main.ipynb#X34sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m onehot_padded_labels \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mone_hot(padded_labels, num_classes\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[1;32mi:\\Bch Khoa\\CO3029\\mini project\\main.ipynb Cell 26\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/B%C3%A1ch%20Khoa/CO3029/mini%20project/main.ipynb#X34sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m sorted_data, sorted_labels \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39msorted\u001b[39m(\u001b[39mzip\u001b[39m(data, labels), key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mlen\u001b[39m(x[\u001b[39m0\u001b[39m]), reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/B%C3%A1ch%20Khoa/CO3029/mini%20project/main.ipynb#X34sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Pad sequences to the length of the longest sequence\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/i%3A/B%C3%A1ch%20Khoa/CO3029/mini%20project/main.ipynb#X34sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m padded_data \u001b[39m=\u001b[39m pad_sequence([torch\u001b[39m.\u001b[39;49mtensor(seq) \u001b[39mfor\u001b[39;00m seq \u001b[39min\u001b[39;00m sorted_data], batch_first\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/B%C3%A1ch%20Khoa/CO3029/mini%20project/main.ipynb#X34sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m padded_labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(sorted_labels, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\n\u001b[0;32m     <a href='vscode-notebook-cell:/i%3A/B%C3%A1ch%20Khoa/CO3029/mini%20project/main.ipynb#X34sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m onehot_padded_labels \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mone_hot(padded_labels, num_classes\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Wrap train_loader with tqdm\n",
    "with tqdm(train_loader, unit=\"batch\") as tepoch:\n",
    "    for epoch in range(epochs):\n",
    "        print(\"Training\")\n",
    "        model.train()\n",
    "        # Wrap train_loader with tqdm to display progress bar\n",
    "        with tqdm(tepoch, unit=\"batch\") as tbatch:\n",
    "            for packed_data, mask, labels in tbatch:\n",
    "                optimizer.zero_grad()\n",
    "                predictions = model(packed_data, mask)\n",
    "                loss = criterion(predictions, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                tbatch.set_postfix(loss=loss.item())\n",
    "\n",
    "        # Evaluation on the test set\n",
    "        print(\"Testing\")\n",
    "        model.eval()\n",
    "        total_acc, total_count = 0, 0\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Wrap test_loader with tqdm to display progress bar\n",
    "            with tqdm(test_loader, unit=\"batch\") as ttest:\n",
    "                for packed_data, mask, labels in ttest:\n",
    "                    predictions = model(packed_data, mask)\n",
    "                    total_acc += (predictions.argmax(1) == labels).sum().item()\n",
    "                    total_count += labels.size(0)\n",
    "                    ttest.set_postfix(accuracy=total_acc / total_count)\n",
    "\n",
    "        accuracy = total_acc / total_count\n",
    "        print(f'Epoch [{epoch+1}/{epochs}] | Test Accuracy: {accuracy:.2%}')\n",
    "\n",
    "# Print total training time\n",
    "print(\"Total training time: {:.2f} seconds\".format(time.time() - start_time))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
